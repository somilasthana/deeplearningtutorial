{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Making-with-CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somilasthana/deeplearningtutorial/blob/master/Making_with_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwWvKN8JjT3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmhNizSVjl2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Theory:\n",
        "\n",
        "CNN applies series of filter on raw pixel data of an image to extract and learn high-level features.\n",
        "\n",
        "1. Convolutional layers:\n",
        "2. Pooling layers\n",
        "3. Dense (fully connected) layers\n",
        "\n",
        "Convolution layers\n",
        "For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. \n",
        "\n",
        "Pooling layers\n",
        "Downsamples or reduces the dimensionality of the feature map in order to decrease processing time.\n",
        "\n",
        "Dense (fully connected) layers\n",
        "Performs the classification on the convoluted downsampled layer\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sBJTxN7lKZO",
        "colab_type": "text"
      },
      "source": [
        "CNN will be build with following architecture\n",
        "\n",
        "\n",
        "\n",
        "*   Convolutional Layer #1 (CL#1) : 32 , 5X5 filters\n",
        "*   Pooling Layer #1 (PL#1) : Max Pooling 2X2 filters stride=2\n",
        "*   CL#2 : 64, 5X5 filters\n",
        "*   PL#2 : Max Pooling 2X2 filter stride=2\n",
        "*   Dense Layer #1(DL#1) : 1,024 neurons , dropout(0.4)\n",
        "*   DL#2 : softmax, 10 neurons\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g47b3SKlBUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model_fn(features, labels, mode):\n",
        "  # Input Layer\n",
        "  \"\"\"Each input tensor expects a shape of [batch_size, image_height, image_width, channels]\n",
        "     The reason for batch_size = -1 so that it can be tuned as a hyperparameter.\n",
        "  \"\"\"\n",
        "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
        "  \n",
        "  \"\"\"CL# 1 [batch_size, 28, 28, 1] ===becomes===> [batch_size, 28, 28, 32]\"\"\"\n",
        "  \n",
        "  conv1 = tf.layers.conv2d(\n",
        "      inputs=input_layer,\n",
        "      filters=32,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu\n",
        "  )\n",
        "  \n",
        "  \"\"\"PL#1 2x2 filter reduces height and width by 50% each.\"\"\"\n",
        "  \"\"\"[batch_size, 28, 28, 32] ===becomes===> [batch_size, 14, 14, 32]\"\"\"\n",
        "  \n",
        "  pool1 = tf.layers.max_pooling2d(\n",
        "      inputs=conv1,\n",
        "      pool_size=[2 ,2],\n",
        "      strides=2\n",
        "  )\n",
        "  \n",
        "  \"\"\"CL# 2 [batch_size, 14, 14, 32] ===becomes===> [batch_size, 14, 14, 64]\"\"\"\n",
        "  \n",
        "  conv2 = tf.layers.conv2d(\n",
        "      inputs=pool1,\n",
        "      filters=64,\n",
        "      kernel_size=[5, 5],\n",
        "      padding=\"same\",\n",
        "      activation=tf.nn.relu\n",
        "  )\n",
        "  \n",
        "  \"\"\"PL#2 [batch_size, 14, 14, 64] ===becomes===> [batch_size, 7, 7, 64]\"\"\"\n",
        "  \n",
        "  \n",
        "  pool2 = tf.layers.max_pooling2d(\n",
        "      inputs=conv2,\n",
        "      pool_size=[2,2],\n",
        "      strides=2\n",
        "  )\n",
        "  \n",
        "  \"\"\"Flatten to feed it to dense layers\"\"\"\n",
        "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
        "  \n",
        "  \"\"\"DL# 1 [batch_size, 3136] ---feeds to ---> 1024 neurons\"\"\"\n",
        "  \"\"\" shape is [batch_size, 1024] \"\"\"\n",
        "  \n",
        "  dense = tf.layers.dense(\n",
        "      inputs=pool2_flat,\n",
        "      units=1024,\n",
        "      activation=tf.nn.relu\n",
        "  )\n",
        "  \n",
        "  # Regularization\n",
        "  \"\"\" No shape change [batch_size, 1024] \"\"\"\n",
        "  dropout = tf.layers.dropout(\n",
        "      inputs=dense,\n",
        "      rate=0.4,\n",
        "      training= mode == tf.estimator.ModeKeys.TRAIN\n",
        "  )\n",
        "  \n",
        "  \"\"\"The output is [batch_size, 10]\"\"\"\n",
        "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
        "  \n",
        "  predictions = {\n",
        "      \"classes\": tf.argmax(input=logits, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
        "  }\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimateSpecs(mode=mode, predictions=predictions)\n",
        "  \n",
        "  # Calculate Loss\n",
        "  \n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
        "  \n",
        "  # Configure the Training Op (for TRAIN mode)\n",
        "  \n",
        "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizier = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
        "    \n",
        "    train_op = optimizier.minimize(\n",
        "        loss=loss,\n",
        "        global_step=tf.train.get_global_step()\n",
        "    )\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "  \n",
        "  \n",
        "  # Add evaluation metrics (for EVAL mode)\n",
        "  eval_metric_ops = {\n",
        "      \"accuracy\": tf.metrics.accuracy(\n",
        "          labels=labels,\n",
        "          predictions=predictions[\"classes\"]\n",
        "      )\n",
        "  }\n",
        "  \n",
        "  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88jkB9RSuu3z",
        "colab_type": "text"
      },
      "source": [
        "Load Training and Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zes9S4Qkuoyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load training and eval data\n",
        "((train_data, train_labels),\n",
        " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_data = train_data/np.float32(255)\n",
        "train_labels = train_labels.astype(np.int32)  # not required\n",
        "\n",
        "eval_data = eval_data/np.float32(255)\n",
        "eval_labels = eval_labels.astype(np.int32)  # not required"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTJub8n3z6X4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "2ba25181-99f0-4cd4-8653-2a41b46f8911"
      },
      "source": [
        "# Create the Estimator\n",
        "# a TensorFlow class for performing high-level model training, evaluation, and inference) for our model\n",
        "mnist_classifier = tf.estimator.Estimator(\n",
        "    model_fn=cnn_model_fn,\n",
        "    model_dir=\"/tmp/mnist_convnet_model\"\n",
        ")\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fba6a6c5f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHlMNEba0lx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x = {\"x\": train_data},\n",
        "    y = train_labels,\n",
        "    batch_size=100,\n",
        "    num_epochs=None,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPdFcWhU1x34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "8a506ed2-2aa6-4ce2-c9b3-b58ed3aee6aa"
      },
      "source": [
        "mnist_classifier.train(\n",
        "    input_fn=train_input_fn,\n",
        "    steps=1\n",
        ")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.2962666, step = 1\n",
            "INFO:tensorflow:Saving checkpoints for 2 into /tmp/mnist_convnet_model/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 2.2962666.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fba6a6c5e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMnyq3-J19k8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c04db6d4-9977-42b7-a9df-59d4598d5669"
      },
      "source": [
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"x\": eval_data},\n",
        "    y=eval_labels,\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "\n",
        "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
        "print(eval_results)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-06-03T10:30:26Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-2\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-06-03-10:30:26\n",
            "INFO:tensorflow:Saving dict for global step 2: accuracy = 0.1354, global_step = 2, loss = 2.2978826\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2: /tmp/mnist_convnet_model/model.ckpt-2\n",
            "{'accuracy': 0.1354, 'loss': 2.2978826, 'global_step': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l77Gu2B-4qgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}