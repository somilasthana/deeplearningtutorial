{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-NLU-101.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somilasthana/deeplearningtutorial/blob/master/BERT_NLU_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLJKlTcornpz",
        "colab_type": "text"
      },
      "source": [
        "Using BERT TF hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJdd3Gx-rQv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1c9ca115-610d-4676-e99d-1c811caafe82"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0530 15:15:05.254896 139819035359104 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBkvDU55r9W1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bcbd5ebd-cbee-487d-e48f-4742f10c5eac"
      },
      "source": [
        "!pip install bert-tensorflow # Need Bert Libraries "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL7_QCpasKxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ZyML1_uBAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = './'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s48T7eItuSkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT7w4u1Eucn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load all files from a directory in a DataFrame.\n",
        "def load_directory_data(directory):\n",
        "  data = {}\n",
        "  data[\"sentence\"] = []\n",
        "  data[\"sentiment\"] = []\n",
        "  \n",
        "  for file_path in os.listdir(directory):\n",
        "    with tf.gfile.GFile(os.path.join(directory, file_path), \"r\") as f:\n",
        "      data[\"sentence\"].append(f.read())\n",
        "      data[\"sentiment\"].append(re.match(\"\\d+_(\\d+)\\.txt\", file_path).group(1))\n",
        "  return pd.DataFrame.from_dict(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMVjYUDRvPAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merge positive and negative examples, add a polarity column and shuffle.\n",
        "def load_dataset(directory):\n",
        "  pos_df = load_directory_data(os.path.join(directory, \"pos\"))\n",
        "  neg_df = load_directory_data(os.path.join(directory, \"neg\"))\n",
        "  pos_df[\"polarity\"] = 1\n",
        "  neg_df[\"polarity\"] = 0\n",
        "  return pd.concat([pos_df, neg_df]).sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reM0bFyAwDuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  dataset = tf.keras.utils.get_file(\n",
        "      \n",
        "      fname=\"aclImdb.tar.gz\", \n",
        "      origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "      extract=True\n",
        "  )\n",
        "  \n",
        "  train_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                       \"aclImdb\", \"train\"))\n",
        "  test_df = load_dataset(os.path.join(os.path.dirname(dataset), \n",
        "                                      \"aclImdb\", \"test\"))\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-z19__TwyLS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "08324db5-88bb-4e4e-dc99-8c4a557c2c2a"
      },
      "source": [
        "train, test = download_and_load_datasets()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEnn97JCw38y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8de9df7-6aec-41bc-a57f-7a27cc9b74db"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 3), (25000, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4UlFMP4xO9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(5000)\n",
        "test = test.sample(5000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8J2axhAxVLm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "057e4175-2b75-4ef7-f143-dd810ff2b258"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijkJBImQxXwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6492bfc4-2644-45c0-c929-76c2bd3d60a7"
      },
      "source": [
        "test.columns"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence', 'sentiment', 'polarity'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP1NDyJkxbo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "label_list=[0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU5Q16vjxuKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "dba83404-2185-4d2e-95a1-5b46a91f12f4"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3719</th>\n",
              "      <td>This is a very grim, hard hitting, even brutal...</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6475</th>\n",
              "      <td>There are bad movies, then there are the movie...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22815</th>\n",
              "      <td>Not only did they get the characters all wrong...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1088</th>\n",
              "      <td>In a far away Galaxy is a planet called Ceta. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4613</th>\n",
              "      <td>Joseph Brady and Clarence Doolittle are two sa...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                sentence sentiment  polarity\n",
              "3719   This is a very grim, hard hitting, even brutal...        10         1\n",
              "6475   There are bad movies, then there are the movie...         3         0\n",
              "22815  Not only did they get the characters all wrong...         1         0\n",
              "1088   In a far away Galaxy is a planet called Ceta. ...         1         0\n",
              "4613   Joseph Brady and Clarence Doolittle are two sa...         9         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tri761nJyD0S",
        "colab_type": "text"
      },
      "source": [
        "Transform our data into a format BERT understands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxSWoh2Px9AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(\n",
        "    \n",
        "    guid=None,\n",
        "    text_a=x[DATA_COLUMN],\n",
        "    text_b=None, # useful in case text_a and text_b has a relation like translation\n",
        "    label=x[LABEL_COLUMN]\n",
        "\n",
        "), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pj4T1ob0L_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(\n",
        "    \n",
        "    guid=None,\n",
        "    text_a=x[DATA_COLUMN],\n",
        "    text_b=None,\n",
        "    label=x[LABEL_COLUMN]\n",
        "    \n",
        "), axis =1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hFo6SV11ViB",
        "colab_type": "text"
      },
      "source": [
        "Next, we need to preprocess our data so that it matches the data BERT was trained on.\n",
        "\n",
        "Lowercase our text (if we're using a BERT lowercase model)\n",
        "\n",
        "Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
        "\n",
        "Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
        "\n",
        "Map our words to indexes using a vocab file that BERT provides\n",
        "\n",
        "Add special \"CLS\" and \"SEP\" tokens (see the readme)\n",
        "\n",
        "Append \"index\" and \"segment\" tokens to each input (see the BERT paper)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmBd0IpH1Qkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvJB5m5V1x5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tokenizer_from_hub_module():\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([\n",
        "          tokenization_info[\"vocab_file\"],\n",
        "          tokenization_info[\"do_lower_case\"]\n",
        "      ])\n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      \n",
        "      vocab_file=vocab_file,\n",
        "      do_lower_case=do_lower_case\n",
        "  \n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P8bzx_H3wFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d2b43356-df37-444e-f06b-c6c36ce10501"
      },
      "source": [
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 15:18:04.480695 139819035359104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 15:18:07.188583 139819035359104 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY8NJMCP30UV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d15146cf-1472-42c2-ff89-ba5af1a5623b"
      },
      "source": [
        "tokenizer.tokenize(\"Trying POC with BERT technique\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trying', 'po', '##c', 'with', 'bert', 'technique']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoRhtT894PRe",
        "colab_type": "text"
      },
      "source": [
        "Using our tokenizer, we'll call run_classifier.convert_examples_to_features on our InputExamples to convert them into features BERT understands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kFxS1xX4B02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT1mgUvc4Ulj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_features = bert.run_classifier.convert_examples_to_features(\n",
        "    train_InputExamples,\n",
        "    label_list,\n",
        "    MAX_SEQ_LENGTH,\n",
        "    tokenizer\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba5Jl8s_4ttA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_features = bert.run_classifier.convert_examples_to_features(\n",
        "    test_InputExamples,\n",
        "    label_list,\n",
        "    MAX_SEQ_LENGTH,\n",
        "    tokenizer\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ9Ap-oI5eyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6771980b-0c26-411c-9ba9-eac9e25f5de6"
      },
      "source": [
        "train_features[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bert.run_classifier.InputFeatures at 0x7f299bfeecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv0RF4TG6d7s",
        "colab_type": "text"
      },
      "source": [
        "Creating a Model\n",
        "\n",
        "First, it loads the BERT tf hub module\n",
        "\n",
        "Next, it creates a single new layer that will be trained to adapt BERT to our sentiment task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIwG96wt58FL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels, num_labels):\n",
        "  \n",
        "  bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
        "  \n",
        "  bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
        "  \n",
        "  bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
        "  \n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  \n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "  \n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "  \n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\",\n",
        "      [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02)\n",
        "  )\n",
        "  \n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\",\n",
        "      [num_labels],\n",
        "      initializer=tf.zeros_initializer()\n",
        "  )\n",
        "  \n",
        "  with tf.variable_scope(\"loss\"):\n",
        "    \n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "    \n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    \n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "    \n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "    \n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    \n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "    \n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels*log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxDUuB37Ef2j",
        "colab_type": "text"
      },
      "source": [
        "Next we'll wrap our model function in a model_fn_builder function that adapts our model to work for training, evaluation, and prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSLxf_zyDFKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
        "  \n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "    \n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    \n",
        "    if not is_predicting:\n",
        "      (loss, predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "      \n",
        "      train_ops = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "      \n",
        "      # Calculate evaluation metrics\n",
        "      \n",
        "      def metrics_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
        "        auc = tf.metrics.auc(label_ids, predicted_labels)\n",
        "        recall = tf.metrics.recall(label_ids, predicted_labels)\n",
        "        precision = tf.metrics.precision(label_ids, predicted_labels)  \n",
        "        true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)\n",
        "        false_pos = tf.metrics.false_positives(label_ids, predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "      \n",
        "      eval_metrics = metrics_fn(label_ids, predicted_labels)\n",
        "      \n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_ops)\n",
        "      \n",
        "      else:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "      \n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      \n",
        "      return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
        "    \n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa3jRqZ2M49a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAINING_EPOCHS = 3.0\n",
        "\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxAe2RGVN8Hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_steps = int(len(train_features) / BATCH_SIZE*NUM_TRAINING_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adVoUlcmOdB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    \n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS\n",
        "\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itzl8RUnPCTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "    num_labels=len(label_list),\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbQhSG4ld4ip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "5af559ba-617e-49b7-a741-7d004fb0bce0"
      },
      "source": [
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': './', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2980fa1be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:04:40.363842 139819035359104 estimator.py:201] Using config: {'_model_dir': './', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2980fa1be0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry4EJPTIP0hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57WU2AFyQa_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "42941dc6-4536-4588-81d6-a66e838a6fc8"
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:04:45.108958 139819035359104 estimator.py:351] Skipping training since max_steps has already saved.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:00:00.015986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzBlUfz8Q922",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLNJlXJ5Re8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "45f57348-296c-4910-fa44-5807702ec0cf"
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:31.523900 139819035359104 estimator.py:1111] Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:36.056493 139819035359104 saver.py:1483] Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:47.750455 139819035359104 estimator.py:1113] Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2019-05-30T16:01:47Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:47.784786 139819035359104 evaluation.py:257] Starting evaluation at 2019-05-30T16:01:47Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:49.666142 139819035359104 monitored_session.py:222] Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0530 16:01:49.679651 139819035359104 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./model.ckpt-468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:49.687999 139819035359104 saver.py:1270] Restoring parameters from ./model.ckpt-468\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:52.337591 139819035359104 session_manager.py:491] Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:01:52.637682 139819035359104 session_manager.py:493] Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2019-05-30-16:03:15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:03:15.424422 139819035359104 evaluation.py:277] Finished evaluation at 2019-05-30-16:03:15\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 468: auc = 0.8671559, eval_accuracy = 0.867, f1_score = 0.8649197, false_negatives = 389.0, false_positives = 276.0, global_step = 468, loss = 0.5121848, precision = 0.88523906, recall = 0.84551233, true_negatives = 2206.0, true_positives = 2129.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:03:15.427202 139819035359104 estimator.py:1979] Saving dict for global step 468: auc = 0.8671559, eval_accuracy = 0.867, f1_score = 0.8649197, false_negatives = 389.0, false_positives = 276.0, global_step = 468, loss = 0.5121848, precision = 0.88523906, recall = 0.84551233, true_negatives = 2206.0, true_positives = 2129.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 468: ./model.ckpt-468\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0530 16:03:19.396086 139819035359104 estimator.py:2039] Saving 'checkpoint_path' summary for global step 468: ./model.ckpt-468\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.8671559,\n",
              " 'eval_accuracy': 0.867,\n",
              " 'f1_score': 0.8649197,\n",
              " 'false_negatives': 389.0,\n",
              " 'false_positives': 276.0,\n",
              " 'global_step': 468,\n",
              " 'loss': 0.5121848,\n",
              " 'precision': 0.88523906,\n",
              " 'recall': 0.84551233,\n",
              " 'true_negatives': 2206.0,\n",
              " 'true_positives': 2129.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF14UjYCRtMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(in_sentences):\n",
        "  labels=[\"Negative\", \"Positive\"]\n",
        "  input_examples = [bert.run_classifier.InputExample(guid=\"\", text_a=x, text_b=None, label=0) for x in in_sentences]\n",
        "  input_features = bert.run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = bert.run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnZndlANTWwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_sentences = [\n",
        "  \"That movie was absolutely awful\",\n",
        "  \"The acting was a bit lacking\",\n",
        "  \"The film was creative and surprising\",\n",
        "  \"Absolutely fantastic!\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZWWK3WwTl-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = get_predictions(pred_sentences)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dTfqhPyfRbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bb3c0a0c-3618-414e-975f-296c054e9263"
      },
      "source": [
        "predictions"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('That movie was absolutely awful',\n",
              "  array([-2.2854893e-03, -6.0822968e+00], dtype=float32),\n",
              "  'Negative'),\n",
              " ('The acting was a bit lacking',\n",
              "  array([-0.03562292, -3.3525236 ], dtype=float32),\n",
              "  'Negative'),\n",
              " ('The film was creative and surprising',\n",
              "  array([-6.1076026e+00, -2.2283979e-03], dtype=float32),\n",
              "  'Positive'),\n",
              " ('Absolutely fantastic!',\n",
              "  array([-5.652477e+00, -3.515019e-03], dtype=float32),\n",
              "  'Positive')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M72tLYKtfSJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}